{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfaac9-349d-454f-8f60-0896f58b32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본코드\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from mmcv import Config\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_model\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint, load_state_dict\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "def uniform_soup(cfg, model, checkpoint_paths ,device = \"cpu\", by_name = False):\n",
    "    dataset = build_dataset(cfg.data.val)\n",
    "    data_loader = build_dataloader(\n",
    "            dataset,\n",
    "            samples_per_gpu=1,\n",
    "            workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "            dist=False,\n",
    "            shuffle=False)  \n",
    "    \n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "        weight_dict = checkpoint['state_dict']\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    \n",
    "    load_state_dict(model, model_dict)\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "    model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "    output = single_gpu_test(model, data_loader)\n",
    "    eval_kwargs = {}\n",
    "    eval_kwargs.update(metric=['mIoU'])\n",
    "    metric = dataset.evaluate(output, **eval_kwargs)\n",
    "    print(f\"mIoU: {metric['mIoU']}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "def greedy_soup(cfg, model_ori, checkpoint_paths, device = \"cpu\"):\n",
    "    dataset = build_dataset(cfg.data.val)\n",
    "    data_loader = build_dataloader(\n",
    "            dataset,\n",
    "            samples_per_gpu=1,\n",
    "            workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "            dist=False,\n",
    "            shuffle=False)  \n",
    "    \n",
    "    result = []\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        model = model_ori.to(device)\n",
    "        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "        model.CLASSES = dataset.CLASSES\n",
    "        model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "        output = single_gpu_test(model, data_loader)\n",
    "        eval_kwargs = {}\n",
    "        eval_kwargs.update(metric=['mIoU'])\n",
    "        metric = dataset.evaluate(output, **eval_kwargs)\n",
    "        result.append((metric['mIoU'],checkpoint_path))\n",
    "        print(f\"리스트에 {i}번째 mIoU {metric['mIoU']}저장\")\n",
    "    \n",
    "    result.sort(key = lambda x : x[0], reverse = True)\n",
    "    print(f\"리스트 정렬\")\n",
    "    print(result)\n",
    "    \n",
    "    model = model_ori.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    pre_metric_value = 0\n",
    "    pre_weight_dict = {}\n",
    "    for i, (mIoU, checkpoint_path) in enumerate(result):\n",
    "        model = model_ori.to(device)\n",
    "        soups = {key:[] for key in model_dict}\n",
    "        now_model_dict = model_dict\n",
    "        if i == 0: 3 4 1 2\n",
    "            checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "            pre_metric_value = mIoU\n",
    "            pre_weight_dict = checkpoint['state_dict']\n",
    "            print(\"soup 모델에 가장 높은 mIou를 가진 checkpoint가 추가되었습니다\")\n",
    "            print(f\"추가된 checkpoint_path: {checkpoint_path}\")\n",
    "            print(f\"현재 최고 mIoU: {pre_metric_value}\")\n",
    "        else:\n",
    "            checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "            weight_dict = checkpoint['state_dict']\n",
    "            \n",
    "            for k, v in pre_weight_dict.items():\n",
    "                soups[k].append(v)\n",
    "            for k, v in weight_dict.items():\n",
    "                soups[k].append(v)    \n",
    "            if 0 < len(soups):\n",
    "                soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "                now_model_dict.update(soups)\n",
    "                \n",
    "                \n",
    "            load_state_dict(model, now_model_dict)\n",
    "            model.CLASSES = dataset.CLASSES\n",
    "            model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "            output = single_gpu_test(model, data_loader)\n",
    "            eval_kwargs = {}\n",
    "            eval_kwargs.update(metric=['mIoU'])\n",
    "            metric = dataset.evaluate(output, **eval_kwargs)\n",
    "            \n",
    "            if metric['mIoU'] >= pre_metric_value:\n",
    "                pre_metric_value = metric['mIoU']\n",
    "                pre_weight_dict = now_model_dict\n",
    "                print(\"soup 모델에 새로운 checkpoint가 추가되었습니다\")\n",
    "                print(f\"추가된 checkpoint_path: {checkpoint_path}\")\n",
    "                print(f\"현재 최고 mIoU: {pre_metric_value}\")\n",
    "            else:\n",
    "                print(\"이번 체크 포인트는 soup 모델에 추가되지 않았습니다\")\n",
    "                print(f\"이번 checkpoint_path: {checkpoint_path}\")\n",
    "                print(f\"현재 최고 mIoU: {pre_metric_value}, 이번 mIou {metric['mIoU']}\")\n",
    "            \n",
    "    model = model_ori.to(device)\n",
    "    load_state_dict(model, pre_weight_dict)\n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc21fc-f3ca-4428-a57b-65bbaf0f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ model cfg path 적기 ################\n",
    "cfg= Config.fromfile('/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k.py')\n",
    "################ model cfg path 적기 ################\n",
    "model = build_segmentor(cfg.model)\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = [\n",
    "    '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/epoch_18.pth',\n",
    "    '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/2_epoch_30.pth',\n",
    "    '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/1_best_mIoU_epoch_12.pth',\n",
    "    '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/epoch_20.pth',\n",
    "]\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa00365-df53-4223-8101-9ade728005b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ save dir path 적기 ################\n",
    "save_dir_path = '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/'\n",
    "name = 'mysoup' # soup 이름 적기\n",
    "################ save dir path 적기 ################\n",
    "\n",
    "print(\"\\n[Uniform Soup]\")\n",
    "uniform_model, checkpoint = uniform_soup(cfg, model, checkpoint_paths, device = device)\n",
    "uniform_dict = checkpoint\n",
    "uniform_dict['state_dict'] = uniform_model.state_dict()\n",
    "\n",
    "torch.save(uniform_dict, save_dir_path+f'uniform_model_soup_{name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0ef31-1255-45dd-9ad3-e867cd81e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ save dir path 적기 ################\n",
    "save_dir_path = '/opt/ml/input/mmseg/work_dirs/knet_s3_upernet_swin-l_8x2_512x512_adamw_80k_ade20k/'\n",
    "name = 'mysoup' # soup 이름 적기\n",
    "################ save dir path 적기 ################\n",
    "\n",
    "print(\"[Greedy Soup (uniform weight update)]\")\n",
    "greedy_model, checkpoint = greedy_soup(cfg, model, checkpoint_paths, device = device)\n",
    "greedy_dict = checkpoint\n",
    "greedy_dict['state_dict'] = greedy_model.state_dict()\n",
    "torch.save(greedy_dict, save_dir_path+f'greedy_model_soup_{name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01062dd-4dd8-4fd7-b5df-56dbe46ae0c0",
   "metadata": {},
   "source": [
    "# Uniform Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d196c72-0e02-4ab6-aba0-af6fc5c322c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Uniform Soup]\n",
      "['/home/jovyan/work/work_space/uijin/archive/swin_k1/best_mDice_iter_200000.pth', '/home/jovyan/work/work_space/uijin/archive/swin_k2/best_mDice_iter_240000.pth', '/home/jovyan/work/work_space/uijin/archive/swin_k3/best_mDice_iter_240000.pth', '/home/jovyan/work/work_space/uijin/archive/swin_k4/best_mDice_iter_192000.pth']\n",
      "Loads checkpoint by local backend from path: /home/jovyan/work/work_space/uijin/archive/swin_k1/best_mDice_iter_200000.pth\n",
      "Loads checkpoint by local backend from path: /home/jovyan/work/work_space/uijin/archive/swin_k1/best_mDice_iter_200000.pth\n",
      "Loads checkpoint by local backend from path: /home/jovyan/work/work_space/uijin/archive/swin_k2/best_mDice_iter_240000.pth\n",
      "Loads checkpoint by local backend from path: /home/jovyan/work/work_space/uijin/archive/swin_k3/best_mDice_iter_240000.pth\n",
      "Loads checkpoint by local backend from path: /home/jovyan/work/work_space/uijin/archive/swin_k4/best_mDice_iter_192000.pth\n",
      "complete!\n"
     ]
    }
   ],
   "source": [
    "# 기본코드\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmengine.runner import load_checkpoint\n",
    "from mmseg.apis import init_model, inference_model\n",
    "\n",
    "def uniform_soup(cfg, checkpoint_paths, device = \"cuda\", by_name = False):\n",
    "    checkpoint = {}\n",
    "    print(checkpoint_paths)        \n",
    "    \n",
    "    model = init_model(config_path, checkpoint_paths[0], device)\n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        model = init_model(config_path, checkpoint_path, device)\n",
    "        model = model.to(device)\n",
    "        model_dict = model.state_dict()\n",
    "        for k, v in model_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "config_path = \"/home/jovyan/work/work_space/uijin/archive/swin_k1/swin_L_K1.py\"\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = [\n",
    "    \"/home/jovyan/work/work_space/uijin/archive/swin_k1/best_mDice_iter_200000.pth\",\n",
    "    \"/home/jovyan/work/work_space/uijin/archive/swin_k2/best_mDice_iter_240000.pth\",\n",
    "    \"/home/jovyan/work/work_space/uijin/archive/swin_k3/best_mDice_iter_240000.pth\",\n",
    "    \"/home/jovyan/work/work_space/uijin/archive/swin_k4/best_mDice_iter_192000.pth\",]\n",
    "\n",
    "################ save dir path 적기 ################\n",
    "save_dir_path = \"\"\n",
    "name = 'mysoup' # soup 이름 적기\n",
    "################ save dir path 적기 ################\n",
    "\n",
    "print(\"\\n[Uniform Soup]\")\n",
    "uniform_model = uniform_soup(config_path, checkpoint_paths, device = device)\n",
    "uniform_dict['state_dict'] = uniform_model.state_dict()\n",
    "torch.save(uniform_model.state_dict(), f'./uniform_model_soup_{name}.pth')\n",
    "print(\"complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcd16d-f41b-4a05-8cee-c926fe807bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dense_crf",
   "language": "python",
   "name": "dense_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
